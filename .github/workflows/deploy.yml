# =============================================================================
# DEPLOY.YML - GitHub Actions Workflow pour Fode-DevOps Infrastructure (CORRIGÃ‰)
# =============================================================================

name: ðŸš€ Fode-DevOps Infrastructure Deployment

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'terraform/**'
      - 'ansible/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'terraform/**'
      - 'ansible/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action Ã  effectuer'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
          - create-backend
          - fix-backend

env:
  TF_VERSION: '1.6.0'
  ANSIBLE_VERSION: '2.15'
  AWS_DEFAULT_REGION: 'eu-west-1'  # âœ… RÃ©gion cohÃ©rente
  BACKEND_BUCKET: 'fode-devops-terraform-state'
  DYNAMODB_TABLE: 'fode-devops-terraform-locks'

jobs:
  # =============================================================================
  # JOB 0: CORRECTION/NETTOYAGE DU BACKEND (NOUVEAU)
  # =============================================================================
  fix-backend:
    name: ðŸ”§ Corriger Backend
    runs-on: ubuntu-latest
    if: github.event.inputs.action == 'fix-backend'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ§¹ Nettoyer les ressources DynamoDB en conflit
      run: |
        echo "ðŸ” VÃ©rification des tables DynamoDB existantes..."
        
        # Lister toutes les tables DynamoDB
        aws dynamodb list-tables --region $AWS_DEFAULT_REGION
        
        # VÃ©rifier si la table existe dans eu-west-1
        if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          echo "âœ… Table DynamoDB existe dÃ©jÃ  dans $AWS_DEFAULT_REGION"
        else
          echo "âŒ Table DynamoDB n'existe pas dans $AWS_DEFAULT_REGION"
          
          # VÃ©rifier si elle existe dans us-east-1
          if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region us-east-1 2>/dev/null; then
            echo "âš ï¸ Table trouvÃ©e dans us-east-1, suppression recommandÃ©e"
            echo "Pour supprimer manuellement:"
            echo "aws dynamodb delete-table --table-name $DYNAMODB_TABLE --region us-east-1"
          fi
        fi
        
    - name: ðŸ”§ RecrÃ©er le backend dans la bonne rÃ©gion
      run: |
        # CrÃ©er le bucket S3 pour l'Ã©tat Terraform
        echo "ðŸ“¦ CrÃ©ation du bucket S3: $BACKEND_BUCKET"
        if ! aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          aws s3 mb s3://$BACKEND_BUCKET --region $AWS_DEFAULT_REGION
          echo "âœ… Bucket S3 crÃ©Ã©"
        else
          echo "âœ… Bucket S3 existe dÃ©jÃ "
        fi
        
        # Activer le versioning
        aws s3api put-bucket-versioning \
          --bucket $BACKEND_BUCKET \
          --versioning-configuration Status=Enabled
        
        # Activer le chiffrement
        aws s3api put-bucket-encryption \
          --bucket $BACKEND_BUCKET \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        # Bloquer l'accÃ¨s public
        aws s3api put-public-access-block \
          --bucket $BACKEND_BUCKET \
          --public-access-block-configuration \
          BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        
        # CrÃ©er la table DynamoDB dans la bonne rÃ©gion
        echo "ðŸ” CrÃ©ation de la table DynamoDB: $DYNAMODB_TABLE dans $AWS_DEFAULT_REGION"
        if ! aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          aws dynamodb create-table \
            --table-name $DYNAMODB_TABLE \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
            --region $AWS_DEFAULT_REGION \
            --tags Key=Name,Value="Terraform State Lock" Key=Project,Value="Fode-DevOps"
          
          # Attendre que la table soit active
          aws dynamodb wait table-exists --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION
          echo "âœ… Table DynamoDB crÃ©Ã©e dans $AWS_DEFAULT_REGION"
        else
          echo "âœ… Table DynamoDB existe dÃ©jÃ  dans $AWS_DEFAULT_REGION"
        fi
        
        echo "ðŸŽ‰ Backend corrigÃ© avec succÃ¨s!"

  # =============================================================================
  # JOB 1: CRÃ‰ATION DU BACKEND S3 (SI NÃ‰CESSAIRE)
  # =============================================================================
  create-backend:
    name: ðŸ—ï¸ CrÃ©er Backend S3
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event.inputs.action == 'create-backend'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ—ï¸ Create S3 Backend Infrastructure
      run: |
        # CrÃ©er le bucket S3 pour l'Ã©tat Terraform
        echo "ðŸ“¦ CrÃ©ation du bucket S3: $BACKEND_BUCKET"
        if ! aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          aws s3 mb s3://$BACKEND_BUCKET --region $AWS_DEFAULT_REGION
          echo "âœ… Bucket S3 crÃ©Ã©"
        else
          echo "âœ… Bucket S3 existe dÃ©jÃ "
        fi
        
        # Activer le versioning
        aws s3api put-bucket-versioning \
          --bucket $BACKEND_BUCKET \
          --versioning-configuration Status=Enabled
        
        # Activer le chiffrement
        aws s3api put-bucket-encryption \
          --bucket $BACKEND_BUCKET \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        # Bloquer l'accÃ¨s public
        aws s3api put-public-access-block \
          --bucket $BACKEND_BUCKET \
          --public-access-block-configuration \
          BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        
        # CrÃ©er la table DynamoDB dans la bonne rÃ©gion
        echo "ðŸ” CrÃ©ation de la table DynamoDB: $DYNAMODB_TABLE"
        if ! aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          aws dynamodb create-table \
            --table-name $DYNAMODB_TABLE \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
            --region $AWS_DEFAULT_REGION \
            --tags Key=Name,Value="Terraform State Lock" Key=Project,Value="Fode-DevOps"
          
          # Attendre que la table soit active
          aws dynamodb wait table-exists --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION
          echo "âœ… Table DynamoDB crÃ©Ã©e"
        else
          echo "âœ… Table DynamoDB existe dÃ©jÃ "
        fi
        
        echo "ðŸŽ‰ Backend infrastructure crÃ©Ã©e avec succÃ¨s!"

  # =============================================================================
  # JOB 2: VÃ‰RIFICATION DU BACKEND
  # =============================================================================
  check-backend:
    name: ðŸ” VÃ©rifier Backend
    runs-on: ubuntu-latest
    if: github.event.inputs.action != 'create-backend' && github.event.inputs.action != 'fix-backend'
    outputs:
      backend_exists: ${{ steps.check.outputs.backend_exists }}
    
    steps:
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ” Check Backend Existence
      id: check
      run: |
        echo "VÃ©rification de l'existence du backend..."
        
        # VÃ©rifier le bucket S3
        if aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          echo "âœ… Bucket S3 existe"
          S3_EXISTS=true
        else
          echo "âŒ Bucket S3 n'existe pas"
          S3_EXISTS=false
        fi
        
        # VÃ©rifier la table DynamoDB dans la bonne rÃ©gion
        if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          echo "âœ… Table DynamoDB existe dans $AWS_DEFAULT_REGION"
          DYNAMODB_EXISTS=true
        else
          echo "âŒ Table DynamoDB n'existe pas dans $AWS_DEFAULT_REGION"
          DYNAMODB_EXISTS=false
        fi
        
        if [ "$S3_EXISTS" = true ] && [ "$DYNAMODB_EXISTS" = true ]; then
          echo "backend_exists=true" >> $GITHUB_OUTPUT
          echo "âœ… Backend infrastructure existe"
        else
          echo "backend_exists=false" >> $GITHUB_OUTPUT
          echo "âŒ Backend infrastructure manquante"
          echo ""
          echo "Pour corriger le backend, exÃ©cutez:"
          echo "gh workflow run deploy.yml --field action=fix-backend"
          exit 1
        fi

  # =============================================================================
  # JOB 3: VALIDATION ET SÃ‰CURITÃ‰
  # =============================================================================
  validation:
    name: ðŸ” Validation et SÃ©curitÃ©
    runs-on: ubuntu-latest
    needs: check-backend
    if: needs.check-backend.outputs.backend_exists == 'true'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        # CrÃ©er le rÃ©pertoire keys dans terraform
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Terraform Format et Auto-correction
      working-directory: ./terraform
      run: |
        # Formater automatiquement tous les fichiers
        terraform fmt -recursive
        
        # VÃ©rifier s'il y a des changements aprÃ¨s formatage
        if ! git diff --quiet; then
          echo "ðŸ“ Fichiers formatÃ©s automatiquement"
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Auto-Format"
          git add .
          git commit -m "ðŸ”§ Auto-format Terraform files [skip ci]"
          git push
          echo "âœ… Changements de formatage committÃ©s automatiquement"
        else
          echo "âœ… Tous les fichiers sont dÃ©jÃ  correctement formatÃ©s"
        fi
      
    - name: âœ… Terraform Validate
      working-directory: ./terraform
      run: |
        terraform init -backend=false
        terraform validate
        
    - name: ðŸ”’ Security Scan avec Checkov
      uses: bridgecrewio/checkov-action@master
      with:
        directory: ./terraform
        framework: terraform
        output_format: cli
      continue-on-error: true

  # =============================================================================
  # JOB 4: TERRAFORM PLAN
  # =============================================================================
  terraform-plan:
    name: ðŸ“‹ Terraform Plan
    runs-on: ubuntu-latest
    needs: [check-backend, validation]
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      needs.validation.result == 'success' &&
      github.event.inputs.action != 'create-backend' &&
      github.event.inputs.action != 'destroy' &&
      github.event.inputs.action != 'fix-backend'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ“¦ Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸ“‹ Terraform Plan
      working-directory: ./terraform
      run: |
        # DÃ©terminer l'environnement basÃ© sur la branche ou l'input
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "ðŸŽ¯ Planification pour l'environnement: $ENVIRONMENT"
        
        terraform plan -out=tfplan \
          -var="project_name=fode-devops" \
          -var="environment=$ENVIRONMENT" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: ðŸ’¾ Save Terraform Plan
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan
        path: ./terraform/tfplan
        retention-days: 30

  # =============================================================================
  # JOB 5: TERRAFORM APPLY
  # =============================================================================
  terraform-apply:
    name: ðŸš€ Terraform Apply
    runs-on: ubuntu-latest
    needs: [check-backend, validation, terraform-plan]
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      needs.validation.result == 'success' &&
      needs.terraform-plan.result == 'success' &&
      (
        (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
        github.event.inputs.action == 'apply'
      )
    environment: production
    outputs:
      load_balancer_dns: ${{ steps.terraform-outputs.outputs.load_balancer_dns }}
      instance_id: ${{ steps.terraform-outputs.outputs.instance_id }}
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ“¦ Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸš€ Terraform Apply
      working-directory: ./terraform
      run: |
        # DÃ©terminer l'environnement (mÃªme logique que terraform-plan)
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "ðŸš€ DÃ©ploiement pour l'environnement: $ENVIRONMENT"
        
        terraform apply -auto-approve \
          -var="project_name=fode-devops" \
          -var="environment=$ENVIRONMENT" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: ðŸ“¤ Export Terraform Outputs
      id: terraform-outputs
      working-directory: ./terraform
      run: |
        # VÃ©rifier si les outputs existent avant de les extraire
        if terraform output load_balancer_dns >/dev/null 2>&1; then
          LB_DNS=$(terraform output -raw load_balancer_dns)
          echo "load_balancer_dns=$LB_DNS" >> $GITHUB_OUTPUT
        else
          echo "load_balancer_dns=non-disponible" >> $GITHUB_OUTPUT
        fi
        
        if terraform output instance_id >/dev/null 2>&1; then
          INSTANCE_ID=$(terraform output -raw instance_id)
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        else
          echo "instance_id=non-disponible" >> $GITHUB_OUTPUT
        fi
        
    - name: ðŸ“Š Create Deployment Summary
      working-directory: ./terraform
      run: |
        # DÃ©terminer l'environnement pour l'affichage
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "## ðŸš€ DÃ©ploiement Fode-DevOps RÃ©ussi!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“‹ Informations du dÃ©ploiement:" >> $GITHUB_STEP_SUMMARY
        echo "- **Instance ID:** ${{ steps.terraform-outputs.outputs.instance_id }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Load Balancer DNS:** ${{ steps.terraform-outputs.outputs.load_balancer_dns }}" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.terraform-outputs.outputs.load_balancer_dns }}" != "non-disponible" ]; then
          echo "- **URL:** http://${{ steps.terraform-outputs.outputs.load_balancer_dns }}" >> $GITHUB_STEP_SUMMARY
        fi
        echo "- **RÃ©gion:** ${{ env.AWS_DEFAULT_REGION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Environnement:** $ENVIRONMENT" >> $GITHUB_STEP_SUMMARY
    # =============================================================================
# JOB 5B: ANSIBLE DEPLOYMENT - VERSION FLEXIBLE (SSM + SSH)
# =============================================================================
  ansible-deployment:
    name: ðŸŽ­ Ansible Deployment (Flexible)
    runs-on: ubuntu-latest
    needs: terraform-apply
    if: |
      always() && 
      needs.terraform-apply.result == 'success'

    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with: 
        python-version: '3.9'
        
    - name: ðŸ“¦ Install Ansible and dependencies
      run: |
        python -m pip install --upgrade pip
        pip install ansible boto3 botocore
        # Installer les collections AWS (pour SSM si nÃ©cessaire)
        ansible-galaxy collection install amazon.aws community.aws
        ansible --version
        
    - name: ðŸ”§ Install AWS Session Manager Plugin
      run: |
        curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb" -o "session-manager-plugin.deb"
        sudo dpkg -i session-manager-plugin.deb
        session-manager-plugin --version
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
        
    - name: ðŸ“¦ Terraform Init (pour les outputs)
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸ” Debug Terraform outputs
      working-directory: ./terraform
      run: |
        echo "ðŸ“‹ Outputs Terraform disponibles:"
        terraform output
        echo ""
        echo "ðŸ” Outputs spÃ©cifiques:"
        echo "Instance ID: $(terraform output -raw instance_id 2>/dev/null || echo 'N/A')"
        echo "Instance Private IP: $(terraform output -raw instance_private_ip 2>/dev/null || echo 'N/A')"
        echo "Load Balancer DNS: $(terraform output -raw load_balancer_dns 2>/dev/null || echo 'N/A')"
        echo "S3 Bucket: $(terraform output -raw s3_bucket_name 2>/dev/null || echo 'N/A')"
    
    - name: ðŸ“¦ ExÃ©cution du script de gÃ©nÃ©ration d'inventaire
      run: |
        python3 ansible/scripts/generate_inventory.py
      working-directory: ${{ github.workspace }}
        
    - name: ðŸ”„ GÃ©nÃ©rer inventaire Ansible
      run: |
        echo "ðŸ“ Structure des rÃ©pertoires:"
        ls -la
        
        # CrÃ©er le rÃ©pertoire inventory si nÃ©cessaire
        mkdir -p ansible/inventory
        
        # Rendre le script exÃ©cutable
        chmod +x ansible/scripts/generate_inventory.py
        
        # ExÃ©cuter le script depuis la racine du projet
        echo "ðŸš€ ExÃ©cution du script de gÃ©nÃ©ration d'inventaire..."
        python3 ansible/scripts/generate_inventory.py
        
        echo ""
        echo "âœ… Inventaire Ansible gÃ©nÃ©rÃ©"
        
        # VÃ©rifier que le fichier a Ã©tÃ© crÃ©Ã©
        if [ -f "ansible/inventory/dynamic_hosts.json" ]; then
          echo "âœ… Fichier d'inventaire crÃ©Ã© avec succÃ¨s"
          echo ""
          echo "ðŸ“„ Contenu de l'inventaire:"
          cat ansible/inventory/dynamic_hosts.json
        else
          echo "âŒ Ã‰chec de la crÃ©ation du fichier d'inventaire"
          exit 1
        fi
        
    - name: ðŸ§ª Extract Instance Info
      id: extract_info
      run: |
        # CrÃ©er un script Python temporaire pour Ã©viter les problÃ¨mes d'indentation
        cat > extract_info.py << 'EOF'
        import json
        import sys

        try:
            with open('ansible/inventory/dynamic_hosts.json', 'r') as f:
                inventory = json.load(f)
                
            # Extraction des informations depuis l'inventaire
            hostvars = inventory.get('_meta', {}).get('hostvars', {})
            server_info = hostvars.get('fode-web-server', {})
            
            connection_type = server_info.get('connection_type', 'unknown')
            instance_id = server_info.get('instance_id', 'N/A')
            ansible_host = server_info.get('ansible_host', 'N/A')
            ansible_connection = server_info.get('ansible_connection', 'ssh')
            
            print(f"CONNECTION_TYPE={connection_type}")
            print(f"INSTANCE_ID={instance_id}")
            print(f"ANSIBLE_HOST={ansible_host}")
            print(f"ANSIBLE_CONNECTION={ansible_connection}")
    
        except Exception as e:
            print(f"CONNECTION_TYPE=error")
            print(f"INSTANCE_ID=N/A")
            print(f"ANSIBLE_HOST=N/A")
            print(f"ANSIBLE_CONNECTION=ssh")
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)
        EOF

        # ExÃ©cuter le script Python et capturer les variables
        python3 extract_info.py > inventory_vars.txt
        
        # Charger les variables dans l'environnement GitHub Actions
        while IFS= read -r line; do
          echo "$line" >> $GITHUB_OUTPUT
          echo "$line"
        done < inventory_vars.txt
        
        # Nettoyer
        rm extract_info.py inventory_vars.txt
        
    - name: ðŸ§ª Test de connectivitÃ©
      run: |
        echo "ðŸ” Variables extraites:"
        echo "Connection Type: ${{ steps.extract_info.outputs.CONNECTION_TYPE }}"
        echo "Instance ID: ${{ steps.extract_info.outputs.INSTANCE_ID }}"
        echo "Ansible Host: ${{ steps.extract_info.outputs.ANSIBLE_HOST }}"
        echo "Ansible Connection: ${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
        
        if [ "${{ steps.extract_info.outputs.CONNECTION_TYPE }}" = "error" ]; then
          echo "âŒ Erreur lors de la lecture de l'inventaire"
          exit 1
        fi
        
        CONNECTION_TYPE="${{ steps.extract_info.outputs.CONNECTION_TYPE }}"
        ANSIBLE_HOST="${{ steps.extract_info.outputs.ANSIBLE_HOST }}"
        INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
        
        case "$CONNECTION_TYPE" in
          "ssm")
            echo "âœ… Configuration SSM dÃ©tectÃ©e"
            
            # VÃ©rifier que l'instance est accessible via SSM
            aws ssm describe-instance-information \
              --filters "Key=InstanceIds,Values=$INSTANCE_ID" \
              --query 'InstanceInformationList[0].PingStatus' \
              --output text > ssm_status.txt
            
            SSM_STATUS=$(cat ssm_status.txt)
            echo "ðŸ“Š Statut SSM: $SSM_STATUS"
            
            if [ "$SSM_STATUS" = "Online" ]; then
              echo "âœ… Instance accessible via SSM"
              
              # Test simple via SSM
              echo "ðŸ§ª Test de commande via SSM..."
              aws ssm send-command \
                --instance-ids "$INSTANCE_ID" \
                --document-name "AWS-RunShellScript" \
                --parameters 'commands=["echo \"SSM Test OK\"","whoami","uptime"]' \
                --output text \
                --query 'Command.CommandId' > command_id.txt
              
              COMMAND_ID=$(cat command_id.txt)
              echo "ðŸ“ Command ID: $COMMAND_ID"
              
              # Attendre et rÃ©cupÃ©rer le rÃ©sultat
              sleep 10
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$INSTANCE_ID" \
                --query 'StandardOutputContent' \
                --output text || echo "âš ï¸ Impossible de rÃ©cupÃ©rer la sortie de la commande"
                
            else
              echo "âŒ Instance non accessible via SSM (Status: $SSM_STATUS)"
              exit 1
            fi
            ;;
            
          "load_balancer"|"public_ip"|"private_ip")
            echo "âœ… Configuration SSH dÃ©tectÃ©e via $CONNECTION_TYPE"
            echo "ðŸŽ¯ HÃ´te cible: $ANSIBLE_HOST"
            
            # Pour SSH, on ne peut pas vraiment tester sans clÃ© SSH
            # Le test se fera avec Ansible directement
            echo "âš ï¸ Test SSH sera effectuÃ© par Ansible (nÃ©cessite une clÃ© SSH configurÃ©e)"
            ;;
            
          *)
            echo "âŒ Type de connexion non supportÃ©: $CONNECTION_TYPE"
            exit 1
            ;;
        esac
          
    - name: ðŸš€ ExÃ©cuter playbook Ansible
      working-directory: ./ansible
      run: |
        echo "ðŸ“ VÃ©rification de la structure Ansible:"
        ls -la
        
        # VÃ©rifier que les fichiers existent
        if [ ! -f "inventory/dynamic_hosts.json" ]; then
          echo "âŒ Fichier d'inventaire manquant"
          exit 1
        fi
        
        if [ ! -f "playbooks/site.yml" ]; then
          echo "âŒ Playbook principal manquant"
          echo "ðŸ“ Contenu du rÃ©pertoire playbooks:"
          ls -la playbooks/ || echo "RÃ©pertoire playbooks non trouvÃ©"
          exit 1
        fi
        
        CONNECTION_TYPE="${{ steps.extract_info.outputs.CONNECTION_TYPE }}"
        ANSIBLE_CONNECTION="${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
        
        echo "ðŸ” Type de connexion: $CONNECTION_TYPE"
        echo "ðŸ” Connexion Ansible: $ANSIBLE_CONNECTION"
        
        # Test de l'inventaire
        echo "ðŸ§ª Test de l'inventaire Ansible:"
        ansible-inventory -i inventory/dynamic_hosts.json --list
        
        echo ""
        echo "ðŸ” Test de connectivitÃ© Ansible:"
        
        # DÃ©finir les timeouts selon le type de connexion
        if [ "$CONNECTION_TYPE" = "ssm" ]; then
          TIMEOUT=180
          CONNECTION_TIMEOUT=120
          echo "â° Utilisation de timeouts Ã©tendus pour SSM"
        else
          TIMEOUT=60
          CONNECTION_TIMEOUT=30
          echo "â° Utilisation de timeouts standards pour SSH"
        fi
        
        # Test de ping (peut Ã©chouer en SSH sans clÃ©)
        ansible all -i inventory/dynamic_hosts.json -m ping -v --timeout=$TIMEOUT || {
          echo "âš ï¸ Test de ping Ã©chouÃ©"
          if [ "$CONNECTION_TYPE" != "ssm" ]; then
            echo "ðŸ“‹ Pour SSH, assurez-vous d'avoir :"
            echo "   - Une clÃ© SSH configurÃ©e"
            echo "   - L'accÃ¨s rÃ©seau au serveur"
            echo "   - Les ports SSH (22) ouverts"
            echo "âš ï¸ Tentative de dÃ©ploiement malgrÃ© l'Ã©chec du ping..."
          else
            echo "âŒ SSM inaccessible"
            exit 1
          fi
        }
        
        echo ""
        echo "ðŸš€ ExÃ©cution du playbook Ansible:"
        ansible-playbook -i inventory/dynamic_hosts.json playbooks/site.yml -v \
          --timeout=$TIMEOUT \
          --connection-timeout=$CONNECTION_TIMEOUT \
          || {
            echo "âŒ Le playbook a Ã©chouÃ©"
            
            if [ "$CONNECTION_TYPE" = "ssm" ]; then
              echo "ðŸ“‹ Diagnostic SSM:"
              ansible all -i inventory/dynamic_hosts.json -m setup -a "filter=ansible_default_ipv4" --timeout=$TIMEOUT || echo "Impossible de rÃ©cupÃ©rer les informations via SSM"
            else
              echo "ðŸ“‹ Diagnostic SSH:"
              echo "   - VÃ©rifiez la configuration de la clÃ© SSH"
              echo "   - VÃ©rifiez l'accÃ¨s rÃ©seau"
              echo "   - VÃ©rifiez les Security Groups"
            fi
            
            exit 1
          }
        
    - name: ðŸ“Š RÃ©sumÃ© du dÃ©ploiement Ansible
      if: always()
      run: |
        echo "## ðŸŽ­ RÃ©sumÃ© du dÃ©ploiement Ansible" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "ansible/inventory/dynamic_hosts.json" ]; then
          CONNECTION_TYPE="${{ steps.extract_info.outputs.CONNECTION_TYPE }}"
          INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
          ANSIBLE_HOST="${{ steps.extract_info.outputs.ANSIBLE_HOST }}"
          ANSIBLE_CONNECTION="${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
          
          echo "- **Instance ID:** $INSTANCE_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **Ansible Host:** $ANSIBLE_HOST" >> $GITHUB_STEP_SUMMARY
          echo "- **Type de connexion:** $CONNECTION_TYPE" >> $GITHUB_STEP_SUMMARY
          echo "- **Connexion Ansible:** $ANSIBLE_CONNECTION" >> $GITHUB_STEP_SUMMARY
          echo "- **Statut:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Inventaire:** âœ… GÃ©nÃ©rÃ©" >> $GITHUB_STEP_SUMMARY
          
          case "$CONNECTION_TYPE" in
            "ssm")
              echo "- **SSM:** âœ… ConfigurÃ©" >> $GITHUB_STEP_SUMMARY
              ;;
            "load_balancer")
              echo "- **Load Balancer:** âœ… ConfigurÃ©" >> $GITHUB_STEP_SUMMARY
              echo "- **URL:** $ANSIBLE_HOST" >> $GITHUB_STEP_SUMMARY
              ;;
            "public_ip")
              echo "- **IP Publique:** âœ… ConfigurÃ©" >> $GITHUB_STEP_SUMMARY
              ;;
            "private_ip")
              echo "- **IP PrivÃ©e:** âœ… ConfigurÃ©" >> $GITHUB_STEP_SUMMARY
              ;;
            *)
              echo "- **Connexion:** âš ï¸ Type non standard" >> $GITHUB_STEP_SUMMARY
              ;;
          esac
        else
          echo "- **Erreur:** Inventaire non gÃ©nÃ©rÃ©" >> $GITHUB_STEP_SUMMARY
        fi

    # =============================================================================
    # JOB 6: TESTS POST-DÃ‰PLOIEMENT
    # =============================================================================
  post-deployment-tests:
      name: ðŸ§ª Tests Post-DÃ©ploiement
      runs-on: ubuntu-latest
      needs: [terraform-apply, ansible-deployment]
      if: |
        always() && 
        needs.terraform-apply.result == 'success' &&
        needs.ansible-deployment.result == 'success' &&
        needs.terraform-apply.outputs.load_balancer_dns != 'non-disponible'
      
      steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
          
      - name: ðŸ§ª Test Load Balancer
        run: |
          # RÃ©cupÃ©rer le DNS du Load Balancer
          LB_DNS="${{ needs.terraform-apply.outputs.load_balancer_dns }}"
          
          if [ "$LB_DNS" = "non-disponible" ] || [ -z "$LB_DNS" ]; then
            echo "âš ï¸ Load Balancer DNS non disponible, skip des tests"
            exit 0
          fi
          
          # Attendre que le Load Balancer soit prÃªt
          echo "â³ Attente du dÃ©marrage du Load Balancer..."
          sleep 120
          
          # Test de connectivitÃ© HTTP
          echo "ðŸŒ Test de connectivitÃ© HTTP via Load Balancer..."
          for i in {1..15}; do
            if curl -f -s http://$LB_DNS; then
              echo "âœ… Load Balancer accessible!"
              break
            else
              echo "â³ Tentative $i/15..."
              sleep 20
            fi
          done
          
          # Test de contenu
          echo "ðŸ“„ Test du contenu..."
          CONTENT=$(curl -s http://$LB_DNS || echo "")
          if echo "$CONTENT" | grep -q "Fode-DevOps\|Welcome\|nginx\|Apache"; then
            echo "âœ… Contenu correct dÃ©tectÃ©!"
          else
            echo "âš ï¸ Contenu inattendu, mais service accessible"
          fi

  # =============================================================================
  # JOB 7: TERRAFORM DESTROY
  # =============================================================================
  terraform-destroy:
    name: ðŸ’¥ Terraform Destroy
    runs-on: ubuntu-latest
    needs: check-backend
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      github.event.inputs.action == 'destroy'
    environment: destruction
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ“¦ Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸ’¥ Terraform Destroy
      working-directory: ./terraform
      run: |
        terraform destroy -auto-approve \
          -var="project_name=fode-devops" \
          -var="environment=prod" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: ðŸ“Š Destruction Summary
      run: |
        echo "## ðŸ’¥ Infrastructure Fode-DevOps DÃ©truite!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âš ï¸ Toutes les ressources ont Ã©tÃ© supprimÃ©es" >> $GITHUB_STEP_SUMMARY
        echo "- **RÃ©gion:** ${{ env.AWS_DEFAULT_REGION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Projet:** fode-devops" >> $GITHUB_STEP_SUMMARY
