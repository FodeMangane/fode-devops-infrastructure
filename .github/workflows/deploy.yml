# =============================================================================
# DEPLOY.YML - GitHub Actions Workflow pour Fode-DevOps Infrastructure (CORRIGÃ‰)
# =============================================================================

name: ðŸš€ Fode-DevOps Infrastructure Deployment

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'terraform/**'
      - 'ansible/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'terraform/**'
      - 'ansible/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action Ã  effectuer'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
          - create-backend
          - fix-backend

env:
  TF_VERSION: '1.6.0'
  ANSIBLE_VERSION: '2.15'
  AWS_DEFAULT_REGION: 'eu-west-1'  # âœ… RÃ©gion cohÃ©rente
  BACKEND_BUCKET: 'fode-devops-terraform-state'
  DYNAMODB_TABLE: 'fode-devops-terraform-locks'

jobs:
  # =============================================================================
  # JOB 0: CORRECTION/NETTOYAGE DU BACKEND (NOUVEAU)
  # =============================================================================
  fix-backend:
    name: ðŸ”§ Corriger Backend
    runs-on: ubuntu-latest
    if: github.event.inputs.action == 'fix-backend'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ§¹ Nettoyer les ressources DynamoDB en conflit
      run: |
        echo "ðŸ” VÃ©rification des tables DynamoDB existantes..."
        
        # Lister toutes les tables DynamoDB
        aws dynamodb list-tables --region $AWS_DEFAULT_REGION
        
        # VÃ©rifier si la table existe dans eu-west-1
        if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          echo "âœ… Table DynamoDB existe dÃ©jÃ  dans $AWS_DEFAULT_REGION"
        else
          echo "âŒ Table DynamoDB n'existe pas dans $AWS_DEFAULT_REGION"
          
          # VÃ©rifier si elle existe dans us-east-1
          if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region us-east-1 2>/dev/null; then
            echo "âš ï¸ Table trouvÃ©e dans us-east-1, suppression recommandÃ©e"
            echo "Pour supprimer manuellement:"
            echo "aws dynamodb delete-table --table-name $DYNAMODB_TABLE --region us-east-1"
          fi
        fi
        
    - name: ðŸ”§ RecrÃ©er le backend dans la bonne rÃ©gion
      run: |
        # CrÃ©er le bucket S3 pour l'Ã©tat Terraform
        echo "ðŸ“¦ CrÃ©ation du bucket S3: $BACKEND_BUCKET"
        if ! aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          aws s3 mb s3://$BACKEND_BUCKET --region $AWS_DEFAULT_REGION
          echo "âœ… Bucket S3 crÃ©Ã©"
        else
          echo "âœ… Bucket S3 existe dÃ©jÃ "
        fi
        
        # Activer le versioning
        aws s3api put-bucket-versioning \
          --bucket $BACKEND_BUCKET \
          --versioning-configuration Status=Enabled
        
        # Activer le chiffrement
        aws s3api put-bucket-encryption \
          --bucket $BACKEND_BUCKET \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        # Bloquer l'accÃ¨s public
        aws s3api put-public-access-block \
          --bucket $BACKEND_BUCKET \
          --public-access-block-configuration \
          BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        
        # CrÃ©er la table DynamoDB dans la bonne rÃ©gion
        echo "ðŸ” CrÃ©ation de la table DynamoDB: $DYNAMODB_TABLE dans $AWS_DEFAULT_REGION"
        if ! aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          aws dynamodb create-table \
            --table-name $DYNAMODB_TABLE \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
            --region $AWS_DEFAULT_REGION \
            --tags Key=Name,Value="Terraform State Lock" Key=Project,Value="Fode-DevOps"
          
          # Attendre que la table soit active
          aws dynamodb wait table-exists --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION
          echo "âœ… Table DynamoDB crÃ©Ã©e dans $AWS_DEFAULT_REGION"
        else
          echo "âœ… Table DynamoDB existe dÃ©jÃ  dans $AWS_DEFAULT_REGION"
        fi
        
        echo "ðŸŽ‰ Backend corrigÃ© avec succÃ¨s!"

  # =============================================================================
  # JOB 1: CRÃ‰ATION DU BACKEND S3 (SI NÃ‰CESSAIRE)
  # =============================================================================
  create-backend:
    name: ðŸ—ï¸ CrÃ©er Backend S3
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event.inputs.action == 'create-backend'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ—ï¸ Create S3 Backend Infrastructure
      run: |
        # CrÃ©er le bucket S3 pour l'Ã©tat Terraform
        echo "ðŸ“¦ CrÃ©ation du bucket S3: $BACKEND_BUCKET"
        if ! aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          aws s3 mb s3://$BACKEND_BUCKET --region $AWS_DEFAULT_REGION
          echo "âœ… Bucket S3 crÃ©Ã©"
        else
          echo "âœ… Bucket S3 existe dÃ©jÃ "
        fi
        
        # Activer le versioning
        aws s3api put-bucket-versioning \
          --bucket $BACKEND_BUCKET \
          --versioning-configuration Status=Enabled
        
        # Activer le chiffrement
        aws s3api put-bucket-encryption \
          --bucket $BACKEND_BUCKET \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        # Bloquer l'accÃ¨s public
        aws s3api put-public-access-block \
          --bucket $BACKEND_BUCKET \
          --public-access-block-configuration \
          BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        
        # CrÃ©er la table DynamoDB dans la bonne rÃ©gion
        echo "ðŸ” CrÃ©ation de la table DynamoDB: $DYNAMODB_TABLE"
        if ! aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          aws dynamodb create-table \
            --table-name $DYNAMODB_TABLE \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
            --region $AWS_DEFAULT_REGION \
            --tags Key=Name,Value="Terraform State Lock" Key=Project,Value="Fode-DevOps"
          
          # Attendre que la table soit active
          aws dynamodb wait table-exists --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION
          echo "âœ… Table DynamoDB crÃ©Ã©e"
        else
          echo "âœ… Table DynamoDB existe dÃ©jÃ "
        fi
        
        echo "ðŸŽ‰ Backend infrastructure crÃ©Ã©e avec succÃ¨s!"

  # =============================================================================
  # JOB 2: VÃ‰RIFICATION DU BACKEND
  # =============================================================================
  check-backend:
    name: ðŸ” VÃ©rifier Backend
    runs-on: ubuntu-latest
    if: github.event.inputs.action != 'create-backend' && github.event.inputs.action != 'fix-backend'
    outputs:
      backend_exists: ${{ steps.check.outputs.backend_exists }}
    
    steps:
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ” Check Backend Existence
      id: check
      run: |
        echo "VÃ©rification de l'existence du backend..."
        
        # VÃ©rifier le bucket S3
        if aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          echo "âœ… Bucket S3 existe"
          S3_EXISTS=true
        else
          echo "âŒ Bucket S3 n'existe pas"
          S3_EXISTS=false
        fi
        
        # VÃ©rifier la table DynamoDB dans la bonne rÃ©gion
        if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          echo "âœ… Table DynamoDB existe dans $AWS_DEFAULT_REGION"
          DYNAMODB_EXISTS=true
        else
          echo "âŒ Table DynamoDB n'existe pas dans $AWS_DEFAULT_REGION"
          DYNAMODB_EXISTS=false
        fi
        
        if [ "$S3_EXISTS" = true ] && [ "$DYNAMODB_EXISTS" = true ]; then
          echo "backend_exists=true" >> $GITHUB_OUTPUT
          echo "âœ… Backend infrastructure existe"
        else
          echo "backend_exists=false" >> $GITHUB_OUTPUT
          echo "âŒ Backend infrastructure manquante"
          echo ""
          echo "Pour corriger le backend, exÃ©cutez:"
          echo "gh workflow run deploy.yml --field action=fix-backend"
          exit 1
        fi

  # =============================================================================
  # JOB 3: VALIDATION ET SÃ‰CURITÃ‰
  # =============================================================================
  validation:
    name: ðŸ” Validation et SÃ©curitÃ©
    runs-on: ubuntu-latest
    needs: check-backend
    if: needs.check-backend.outputs.backend_exists == 'true'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        # CrÃ©er le rÃ©pertoire keys dans terraform
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Terraform Format et Auto-correction
      working-directory: ./terraform
      run: |
        # Formater automatiquement tous les fichiers
        terraform fmt -recursive
        
        # VÃ©rifier s'il y a des changements aprÃ¨s formatage
        if ! git diff --quiet; then
          echo "ðŸ“ Fichiers formatÃ©s automatiquement"
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Auto-Format"
          git add .
          git commit -m "ðŸ”§ Auto-format Terraform files [skip ci]"
          git push
          echo "âœ… Changements de formatage committÃ©s automatiquement"
        else
          echo "âœ… Tous les fichiers sont dÃ©jÃ  correctement formatÃ©s"
        fi
      
    - name: âœ… Terraform Validate
      working-directory: ./terraform
      run: |
        terraform init -backend=false
        terraform validate
        
    - name: ðŸ”’ Security Scan avec Checkov
      uses: bridgecrewio/checkov-action@master
      with:
        directory: ./terraform
        framework: terraform
        output_format: cli
      continue-on-error: true

  # =============================================================================
  # JOB 4: TERRAFORM PLAN
  # =============================================================================
  terraform-plan:
    name: ðŸ“‹ Terraform Plan
    runs-on: ubuntu-latest
    needs: [check-backend, validation]
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      needs.validation.result == 'success' &&
      github.event.inputs.action != 'create-backend' &&
      github.event.inputs.action != 'destroy' &&
      github.event.inputs.action != 'fix-backend'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ“¦ Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸ“‹ Terraform Plan
      working-directory: ./terraform
      run: |
        # DÃ©terminer l'environnement basÃ© sur la branche ou l'input
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "ðŸŽ¯ Planification pour l'environnement: $ENVIRONMENT"
        
        terraform plan -out=tfplan \
          -var="project_name=fode-devops" \
          -var="environment=$ENVIRONMENT" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: ðŸ’¾ Save Terraform Plan
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan
        path: ./terraform/tfplan
        retention-days: 30

  # =============================================================================
  # JOB 5: TERRAFORM APPLY
  # =============================================================================
  terraform-apply:
    name: ðŸš€ Terraform Apply
    runs-on: ubuntu-latest
    needs: [check-backend, validation, terraform-plan]
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      needs.validation.result == 'success' &&
      needs.terraform-plan.result == 'success' &&
      (
        (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
        github.event.inputs.action == 'apply'
      )
    environment: production
    outputs:
      load_balancer_dns: ${{ steps.terraform-outputs.outputs.load_balancer_dns }}
      instance_id: ${{ steps.terraform-outputs.outputs.instance_id }}
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ“¦ Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸš€ Terraform Apply
      working-directory: ./terraform
      run: |
        # DÃ©terminer l'environnement (mÃªme logique que terraform-plan)
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "ðŸš€ DÃ©ploiement pour l'environnement: $ENVIRONMENT"
        
        terraform apply -auto-approve \
          -var="project_name=fode-devops" \
          -var="environment=$ENVIRONMENT" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: ðŸ“¤ Export Terraform Outputs
      id: terraform-outputs
      working-directory: ./terraform
      run: |
        # VÃ©rifier si les outputs existent avant de les extraire
        if terraform output load_balancer_dns >/dev/null 2>&1; then
          LB_DNS=$(terraform output -raw load_balancer_dns)
          echo "load_balancer_dns=$LB_DNS" >> $GITHUB_OUTPUT
        else
          echo "load_balancer_dns=non-disponible" >> $GITHUB_OUTPUT
        fi
        
        if terraform output instance_id >/dev/null 2>&1; then
          INSTANCE_ID=$(terraform output -raw instance_id)
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        else
          echo "instance_id=non-disponible" >> $GITHUB_OUTPUT
        fi
        
    - name: ðŸ“Š Create Deployment Summary
      working-directory: ./terraform
      run: |
        # DÃ©terminer l'environnement pour l'affichage
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "## ðŸš€ DÃ©ploiement Fode-DevOps RÃ©ussi!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“‹ Informations du dÃ©ploiement:" >> $GITHUB_STEP_SUMMARY
        echo "- **Instance ID:** ${{ steps.terraform-outputs.outputs.instance_id }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Load Balancer DNS:** ${{ steps.terraform-outputs.outputs.load_balancer_dns }}" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.terraform-outputs.outputs.load_balancer_dns }}" != "non-disponible" ]; then
          echo "- **URL:** http://${{ steps.terraform-outputs.outputs.load_balancer_dns }}" >> $GITHUB_STEP_SUMMARY
        fi
        echo "- **RÃ©gion:** ${{ env.AWS_DEFAULT_REGION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Environnement:** $ENVIRONMENT" >> $GITHUB_STEP_SUMMARY
    # =============================================================================
    # JOB 5B: ANSIBLE DEPLOYMENT - SSM ONLY
    # =============================================================================
  ansible-deployment:
    name: ðŸŽ­ Ansible Deployment (SSM)
    runs-on: ubuntu-latest
    needs: terraform-apply
    if: |
      always() && 
      needs.terraform-apply.result == 'success'

    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with: 
        python-version: '3.9'
        
    - name: ðŸ“¦ Install Ansible and dependencies
      run: |
        python -m pip install --upgrade pip
        pip install ansible boto3 botocore
        # Installer les collections AWS pour SSM
        ansible-galaxy collection install amazon.aws community.aws
        ansible --version
        
    - name: ðŸ”§ Install AWS Session Manager Plugin
      run: |
        curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb" -o "session-manager-plugin.deb"
        sudo dpkg -i session-manager-plugin.deb
        session-manager-plugin --version
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
        
    - name: ðŸ“¦ Terraform Init (pour les outputs)
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸ” Debug Terraform outputs
      working-directory: ./terraform
      run: |
        echo "ðŸ“‹ Outputs Terraform disponibles:"
        terraform output
        echo ""
        echo "ðŸ” Outputs spÃ©cifiques:"
        echo "Instance ID: $(terraform output -raw instance_id 2>/dev/null || echo 'N/A')"
        echo "S3 Bucket: $(terraform output -raw s3_bucket_name 2>/dev/null || echo 'N/A')"
        
    - name: ðŸ”„ GÃ©nÃ©rer inventaire Ansible
      run: |
        echo "ðŸ“ Structure des rÃ©pertoires:"
        ls -la
        
        # CrÃ©er le rÃ©pertoire inventory si nÃ©cessaire
        mkdir -p ansible/inventory
        
        # Rendre le script exÃ©cutable
        chmod +x ansible/scripts/generate_inventory.py
        
        # ExÃ©cuter le script depuis la racine du projet
        echo "ðŸš€ ExÃ©cution du script de gÃ©nÃ©ration d'inventaire..."
        python3 ansible/scripts/generate_inventory.py
        
        echo ""
        echo "âœ… Inventaire Ansible gÃ©nÃ©rÃ©"
        
        # VÃ©rifier que le fichier a Ã©tÃ© crÃ©Ã©
        if [ -f "ansible/inventory/dynamic_hosts.json" ]; then
          echo "âœ… Fichier d'inventaire crÃ©Ã© avec succÃ¨s"
          echo ""
          echo "ðŸ“„ Contenu de l'inventaire:"
          cat ansible/inventory/dynamic_hosts.json
        else
          echo "âŒ Ã‰chec de la crÃ©ation du fichier d'inventaire"
          exit 1
        fi
        
    - name: ðŸ§ª Extract Instance Info
      id: extract_info
      run: |
        # CrÃ©er un script Python temporaire pour extraire les informations SSM
        cat > extract_info.py << 'EOF'
        import json
        import sys

        try:
            with open('ansible/inventory/dynamic_hosts.json', 'r') as f:
                inventory = json.load(f)
                
            # Extraction des informations depuis l'inventaire
            hostvars = inventory.get('_meta', {}).get('hostvars', {})
            server_info = hostvars.get('fode-web-server', {})
            
            instance_id = server_info.get('instance_id', 'N/A')
            ansible_connection = server_info.get('ansible_connection', 'aws_ssm')
            
            # Forcer la connexion SSM
            if ansible_connection != 'aws_ssm':
                print(f"âš ï¸ Connexion forcÃ©e vers SSM (Ã©tait: {ansible_connection})")
                ansible_connection = 'aws_ssm'
            
            print(f"INSTANCE_ID={instance_id}")
            print(f"ANSIBLE_CONNECTION={ansible_connection}")
    
        except Exception as e:
            print(f"INSTANCE_ID=N/A")
            print(f"ANSIBLE_CONNECTION=aws_ssm")
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)
        EOF

        # ExÃ©cuter le script Python et capturer les variables
        python3 extract_info.py > inventory_vars.txt
        
        # Charger les variables dans l'environnement GitHub Actions
        while IFS= read -r line; do
          echo "$line" >> $GITHUB_OUTPUT
          echo "$line"
        done < inventory_vars.txt
        
        # Nettoyer
        rm extract_info.py inventory_vars.txt
        
    - name: ðŸ§ª Test de connectivitÃ© SSM
      run: |
        echo "ðŸ” Variables extraites:"
        echo "Instance ID: ${{ steps.extract_info.outputs.INSTANCE_ID }}"
        echo "Ansible Connection: ${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
        
        INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
        
        if [ "$INSTANCE_ID" = "N/A" ]; then
          echo "âŒ Instance ID non trouvÃ©"
          exit 1
        fi
        
        echo "âœ… Configuration SSM dÃ©tectÃ©e"
        
        # VÃ©rifier que l'instance est accessible via SSM
        aws ssm describe-instance-information \
          --filters "Key=InstanceIds,Values=$INSTANCE_ID" \
          --query 'InstanceInformationList[0].PingStatus' \
          --output text > ssm_status.txt
        
        SSM_STATUS=$(cat ssm_status.txt)
        echo "ðŸ“Š Statut SSM: $SSM_STATUS"
        
        if [ "$SSM_STATUS" = "Online" ]; then
          echo "âœ… Instance accessible via SSM"
          
          # Test simple via SSM
          echo "ðŸ§ª Test de commande via SSM..."
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["echo \"SSM Test OK\"","whoami","uptime"]' \
            --output text \
            --query 'Command.CommandId' > command_id.txt
          
          COMMAND_ID=$(cat command_id.txt)
          echo "ðŸ“ Command ID: $COMMAND_ID"
          
          # Attendre et rÃ©cupÃ©rer le rÃ©sultat
          sleep 10
          aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --query 'StandardOutputContent' \
            --output text || echo "âš ï¸ Impossible de rÃ©cupÃ©rer la sortie de la commande"
            
        else
          echo "âŒ Instance non accessible via SSM (Status: $SSM_STATUS)"
          echo "ðŸ“‹ VÃ©rifications nÃ©cessaires :"
          echo "   - L'instance doit avoir le SSM Agent installÃ©"
          echo "   - L'instance doit avoir un rÃ´le IAM avec les permissions SSM"
          echo "   - L'instance doit Ãªtre dans un sous-rÃ©seau avec accÃ¨s Ã  Internet ou VPC endpoints"
          exit 1
        fi
          
    - name: ðŸš€ ExÃ©cuter playbook Ansible
      working-directory: ./ansible
      run: |
        echo "ðŸ“ VÃ©rification de la structure Ansible:"
        ls -la
        
        # VÃ©rifier que les fichiers existent
        if [ ! -f "inventory/dynamic_hosts.json" ]; then
          echo "âŒ Fichier d'inventaire manquant"
          exit 1
        fi
        
        if [ ! -f "playbooks/site.yml" ]; then
          echo "âŒ Playbook principal manquant"
          echo "ðŸ“ Contenu du rÃ©pertoire playbooks:"
          ls -la playbooks/ || echo "RÃ©pertoire playbooks non trouvÃ©"
          exit 1
        fi
        
        INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
        
        echo "ðŸ” Instance ID: $INSTANCE_ID"
        echo "ðŸ” Connexion: AWS SSM"
        
        # Test de l'inventaire
        echo "ðŸ§ª Test de l'inventaire Ansible:"
        ansible-inventory -i inventory/dynamic_hosts.json --list
        
        echo ""
        echo "ðŸ” Test de connectivitÃ© Ansible via SSM:"
        
        # Utiliser des timeouts Ã©tendus pour SSM
        TIMEOUT=180
        CONNECTION_TIMEOUT=120
        echo "â° Utilisation de timeouts Ã©tendus pour SSM"
        
        # Test de ping SSM
        ansible all -i inventory/dynamic_hosts.json -m ping -v --timeout=$TIMEOUT || {
          echo "âŒ Test de ping SSM Ã©chouÃ©"
          echo "ðŸ“‹ Diagnostic SSM:"
          echo "   - VÃ©rifiez que l'instance a le SSM Agent"
          echo "   - VÃ©rifiez les permissions IAM"
          echo "   - VÃ©rifiez la connectivitÃ© rÃ©seau"
          exit 1
        }
        
        echo ""
        echo "ðŸš€ ExÃ©cution du playbook Ansible via SSM:"
        ansible-playbook -i inventory/dynamic_hosts.json playbooks/site.yml -v \
          --timeout=$TIMEOUT \
          --connection-timeout=$CONNECTION_TIMEOUT \
          || {
            echo "âŒ Le playbook a Ã©chouÃ©"
            
            echo "ðŸ“‹ Diagnostic SSM dÃ©taillÃ©:"
            ansible all -i inventory/dynamic_hosts.json -m setup -a "filter=ansible_default_ipv4" --timeout=$TIMEOUT || echo "Impossible de rÃ©cupÃ©rer les informations systÃ¨me via SSM"
            
            echo "ðŸ“‹ VÃ©rifications SSM recommandÃ©es:"
            echo "   - Instance SSM Agent: sudo systemctl status amazon-ssm-agent"
            echo "   - Logs SSM: /var/log/amazon/ssm/"
            echo "   - Permissions IAM: AmazonSSMManagedInstanceCore"
            
            exit 1
          }
        
    - name: ðŸ“Š RÃ©sumÃ© du dÃ©ploiement Ansible
      if: always()
      run: |
        echo "## ðŸŽ­ RÃ©sumÃ© du dÃ©ploiement Ansible (SSM)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "ansible/inventory/dynamic_hosts.json" ]; then
          INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
          ANSIBLE_CONNECTION="${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
          
          echo "- **Instance ID:** $INSTANCE_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **Type de connexion:** AWS Systems Manager (SSM)" >> $GITHUB_STEP_SUMMARY
          echo "- **Connexion Ansible:** $ANSIBLE_CONNECTION" >> $GITHUB_STEP_SUMMARY
          echo "- **Statut:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Inventaire:** âœ… GÃ©nÃ©rÃ©" >> $GITHUB_STEP_SUMMARY
          echo "- **SSM:** âœ… ConfigurÃ© et testÃ©" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "- **DÃ©ploiement:** âœ… RÃ©ussi" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **DÃ©ploiement:** âŒ Ã‰chec" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ”§ DÃ©pannage SSM" >> $GITHUB_STEP_SUMMARY
            echo "- VÃ©rifiez le statut du SSM Agent sur l'instance" >> $GITHUB_STEP_SUMMARY
            echo "- VÃ©rifiez les permissions IAM (AmazonSSMManagedInstanceCore)" >> $GITHUB_STEP_SUMMARY
            echo "- VÃ©rifiez la connectivitÃ© rÃ©seau (Internet ou VPC endpoints)" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "- **Erreur:** Inventaire non gÃ©nÃ©rÃ©" >> $GITHUB_STEP_SUMMARY
        fi

    # =============================================================================
    # JOB 6: TESTS POST-DÃ‰PLOIEMENT
    # =============================================================================
  post-deployment-tests:
      name: ðŸ§ª Tests Post-DÃ©ploiement
      runs-on: ubuntu-latest
      needs: [terraform-apply, ansible-deployment]
      if: |
        always() && 
        needs.terraform-apply.result == 'success' &&
        needs.ansible-deployment.result == 'success' &&
        needs.terraform-apply.outputs.load_balancer_dns != 'non-disponible'
      
      steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
          
      - name: ðŸ§ª Test Load Balancer
        run: |
          # RÃ©cupÃ©rer le DNS du Load Balancer
          LB_DNS="${{ needs.terraform-apply.outputs.load_balancer_dns }}"
          
          if [ "$LB_DNS" = "non-disponible" ] || [ -z "$LB_DNS" ]; then
            echo "âš ï¸ Load Balancer DNS non disponible, skip des tests"
            exit 0
          fi
          
          # Attendre que le Load Balancer soit prÃªt
          echo "â³ Attente du dÃ©marrage du Load Balancer..."
          sleep 120
          
          # Test de connectivitÃ© HTTP
          echo "ðŸŒ Test de connectivitÃ© HTTP via Load Balancer..."
          for i in {1..15}; do
            if curl -f -s http://$LB_DNS; then
              echo "âœ… Load Balancer accessible!"
              break
            else
              echo "â³ Tentative $i/15..."
              sleep 20
            fi
          done
          
          # Test de contenu
          echo "ðŸ“„ Test du contenu..."
          CONTENT=$(curl -s http://$LB_DNS || echo "")
          if echo "$CONTENT" | grep -q "Fode-DevOps\|Welcome\|nginx\|Apache"; then
            echo "âœ… Contenu correct dÃ©tectÃ©!"
          else
            echo "âš ï¸ Contenu inattendu, mais service accessible"
          fi

  # =============================================================================
  # JOB 7: TERRAFORM DESTROY
  # =============================================================================
  terraform-destroy:
    name: ðŸ’¥ Terraform Destroy
    runs-on: ubuntu-latest
    needs: check-backend
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      github.event.inputs.action == 'destroy'
    environment: destruction
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ”§ Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: ðŸ”‘ Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: ðŸ” Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: ðŸ“¦ Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: ðŸ’¥ Terraform Destroy
      working-directory: ./terraform
      run: |
        terraform destroy -auto-approve \
          -var="project_name=fode-devops" \
          -var="environment=prod" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: ðŸ“Š Destruction Summary
      run: |
        echo "## ðŸ’¥ Infrastructure Fode-DevOps DÃ©truite!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âš ï¸ Toutes les ressources ont Ã©tÃ© supprimÃ©es" >> $GITHUB_STEP_SUMMARY
        echo "- **RÃ©gion:** ${{ env.AWS_DEFAULT_REGION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Projet:** fode-devops" >> $GITHUB_STEP_SUMMARY