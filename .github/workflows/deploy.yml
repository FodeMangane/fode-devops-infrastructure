# =============================================================================
# DEPLOY.YML - GitHub Actions Workflow pour Fode-DevOps Infrastructure (CORRIGÉ)
# =============================================================================

name: 🚀 Fode-DevOps Infrastructure Deployment

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'terraform/**'
      - 'ansible/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'terraform/**'
      - 'ansible/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action à effectuer'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
          - create-backend
          - fix-backend

env:
  TF_VERSION: '1.6.0'
  ANSIBLE_VERSION: '2.15'
  AWS_DEFAULT_REGION: 'eu-west-1'  # ✅ Région cohérente
  BACKEND_BUCKET: 'fode-devops-terraform-state'
  DYNAMODB_TABLE: 'fode-devops-terraform-locks'

jobs:
  # =============================================================================
  # JOB 0: CORRECTION/NETTOYAGE DU BACKEND (NOUVEAU)
  # =============================================================================
  fix-backend:
    name: 🔧 Corriger Backend
    runs-on: ubuntu-latest
    if: github.event.inputs.action == 'fix-backend'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 🧹 Nettoyer les ressources DynamoDB en conflit
      run: |
        echo "🔍 Vérification des tables DynamoDB existantes..."
        
        # Lister toutes les tables DynamoDB
        aws dynamodb list-tables --region $AWS_DEFAULT_REGION
        
        # Vérifier si la table existe dans eu-west-1
        if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          echo "✅ Table DynamoDB existe déjà dans $AWS_DEFAULT_REGION"
        else
          echo "❌ Table DynamoDB n'existe pas dans $AWS_DEFAULT_REGION"
          
          # Vérifier si elle existe dans us-east-1
          if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region us-east-1 2>/dev/null; then
            echo "⚠️ Table trouvée dans us-east-1, suppression recommandée"
            echo "Pour supprimer manuellement:"
            echo "aws dynamodb delete-table --table-name $DYNAMODB_TABLE --region us-east-1"
          fi
        fi
        
    - name: 🔧 Recréer le backend dans la bonne région
      run: |
        # Créer le bucket S3 pour l'état Terraform
        echo "📦 Création du bucket S3: $BACKEND_BUCKET"
        if ! aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          aws s3 mb s3://$BACKEND_BUCKET --region $AWS_DEFAULT_REGION
          echo "✅ Bucket S3 créé"
        else
          echo "✅ Bucket S3 existe déjà"
        fi
        
        # Activer le versioning
        aws s3api put-bucket-versioning \
          --bucket $BACKEND_BUCKET \
          --versioning-configuration Status=Enabled
        
        # Activer le chiffrement
        aws s3api put-bucket-encryption \
          --bucket $BACKEND_BUCKET \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        # Bloquer l'accès public
        aws s3api put-public-access-block \
          --bucket $BACKEND_BUCKET \
          --public-access-block-configuration \
          BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        
        # Créer la table DynamoDB dans la bonne région
        echo "🔐 Création de la table DynamoDB: $DYNAMODB_TABLE dans $AWS_DEFAULT_REGION"
        if ! aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          aws dynamodb create-table \
            --table-name $DYNAMODB_TABLE \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
            --region $AWS_DEFAULT_REGION \
            --tags Key=Name,Value="Terraform State Lock" Key=Project,Value="Fode-DevOps"
          
          # Attendre que la table soit active
          aws dynamodb wait table-exists --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION
          echo "✅ Table DynamoDB créée dans $AWS_DEFAULT_REGION"
        else
          echo "✅ Table DynamoDB existe déjà dans $AWS_DEFAULT_REGION"
        fi
        
        echo "🎉 Backend corrigé avec succès!"

  # =============================================================================
  # JOB 1: CRÉATION DU BACKEND S3 (SI NÉCESSAIRE)
  # =============================================================================
  create-backend:
    name: 🏗️ Créer Backend S3
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event.inputs.action == 'create-backend'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 🏗️ Create S3 Backend Infrastructure
      run: |
        # Créer le bucket S3 pour l'état Terraform
        echo "📦 Création du bucket S3: $BACKEND_BUCKET"
        if ! aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          aws s3 mb s3://$BACKEND_BUCKET --region $AWS_DEFAULT_REGION
          echo "✅ Bucket S3 créé"
        else
          echo "✅ Bucket S3 existe déjà"
        fi
        
        # Activer le versioning
        aws s3api put-bucket-versioning \
          --bucket $BACKEND_BUCKET \
          --versioning-configuration Status=Enabled
        
        # Activer le chiffrement
        aws s3api put-bucket-encryption \
          --bucket $BACKEND_BUCKET \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        # Bloquer l'accès public
        aws s3api put-public-access-block \
          --bucket $BACKEND_BUCKET \
          --public-access-block-configuration \
          BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
        
        # Créer la table DynamoDB dans la bonne région
        echo "🔐 Création de la table DynamoDB: $DYNAMODB_TABLE"
        if ! aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          aws dynamodb create-table \
            --table-name $DYNAMODB_TABLE \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
            --region $AWS_DEFAULT_REGION \
            --tags Key=Name,Value="Terraform State Lock" Key=Project,Value="Fode-DevOps"
          
          # Attendre que la table soit active
          aws dynamodb wait table-exists --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION
          echo "✅ Table DynamoDB créée"
        else
          echo "✅ Table DynamoDB existe déjà"
        fi
        
        echo "🎉 Backend infrastructure créée avec succès!"

  # =============================================================================
  # JOB 2: VÉRIFICATION DU BACKEND
  # =============================================================================
  check-backend:
    name: 🔍 Vérifier Backend
    runs-on: ubuntu-latest
    if: github.event.inputs.action != 'create-backend' && github.event.inputs.action != 'fix-backend'
    outputs:
      backend_exists: ${{ steps.check.outputs.backend_exists }}
    
    steps:
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 🔍 Check Backend Existence
      id: check
      run: |
        echo "Vérification de l'existence du backend..."
        
        # Vérifier le bucket S3
        if aws s3 ls s3://$BACKEND_BUCKET 2>/dev/null; then
          echo "✅ Bucket S3 existe"
          S3_EXISTS=true
        else
          echo "❌ Bucket S3 n'existe pas"
          S3_EXISTS=false
        fi
        
        # Vérifier la table DynamoDB dans la bonne région
        if aws dynamodb describe-table --table-name $DYNAMODB_TABLE --region $AWS_DEFAULT_REGION 2>/dev/null; then
          echo "✅ Table DynamoDB existe dans $AWS_DEFAULT_REGION"
          DYNAMODB_EXISTS=true
        else
          echo "❌ Table DynamoDB n'existe pas dans $AWS_DEFAULT_REGION"
          DYNAMODB_EXISTS=false
        fi
        
        if [ "$S3_EXISTS" = true ] && [ "$DYNAMODB_EXISTS" = true ]; then
          echo "backend_exists=true" >> $GITHUB_OUTPUT
          echo "✅ Backend infrastructure existe"
        else
          echo "backend_exists=false" >> $GITHUB_OUTPUT
          echo "❌ Backend infrastructure manquante"
          echo ""
          echo "Pour corriger le backend, exécutez:"
          echo "gh workflow run deploy.yml --field action=fix-backend"
          exit 1
        fi

  # =============================================================================
  # JOB 3: VALIDATION ET SÉCURITÉ
  # =============================================================================
  validation:
    name: 🔍 Validation et Sécurité
    runs-on: ubuntu-latest
    needs: check-backend
    if: needs.check-backend.outputs.backend_exists == 'true'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🔧 Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: 🔑 Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        # Créer le répertoire keys dans terraform
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: 🔍 Terraform Format et Auto-correction
      working-directory: ./terraform
      run: |
        # Formater automatiquement tous les fichiers
        terraform fmt -recursive
        
        # Vérifier s'il y a des changements après formatage
        if ! git diff --quiet; then
          echo "📝 Fichiers formatés automatiquement"
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Auto-Format"
          git add .
          git commit -m "🔧 Auto-format Terraform files [skip ci]"
          git push
          echo "✅ Changements de formatage committés automatiquement"
        else
          echo "✅ Tous les fichiers sont déjà correctement formatés"
        fi
      
    - name: ✅ Terraform Validate
      working-directory: ./terraform
      run: |
        terraform init -backend=false
        terraform validate
        
    - name: 🔒 Security Scan avec Checkov
      uses: bridgecrewio/checkov-action@master
      with:
        directory: ./terraform
        framework: terraform
        output_format: cli
      continue-on-error: true

  # =============================================================================
  # JOB 4: TERRAFORM PLAN
  # =============================================================================
  terraform-plan:
    name: 📋 Terraform Plan
    runs-on: ubuntu-latest
    needs: [check-backend, validation]
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      needs.validation.result == 'success' &&
      github.event.inputs.action != 'create-backend' &&
      github.event.inputs.action != 'destroy' &&
      github.event.inputs.action != 'fix-backend'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🔧 Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: 🔑 Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 📦 Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: 📋 Terraform Plan
      working-directory: ./terraform
      run: |
        # Déterminer l'environnement basé sur la branche ou l'input
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "🎯 Planification pour l'environnement: $ENVIRONMENT"
        
        terraform plan -out=tfplan \
          -var="project_name=fode-devops" \
          -var="environment=$ENVIRONMENT" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: 💾 Save Terraform Plan
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan
        path: ./terraform/tfplan
        retention-days: 30

  # =============================================================================
  # JOB 5: TERRAFORM APPLY
  # =============================================================================
  terraform-apply:
    name: 🚀 Terraform Apply
    runs-on: ubuntu-latest
    needs: [check-backend, validation, terraform-plan]
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      needs.validation.result == 'success' &&
      needs.terraform-plan.result == 'success' &&
      (
        (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
        github.event.inputs.action == 'apply'
      )
    environment: production
    outputs:
      load_balancer_dns: ${{ steps.terraform-outputs.outputs.load_balancer_dns }}
      instance_id: ${{ steps.terraform-outputs.outputs.instance_id }}
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🔧 Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
        
    - name: 🔑 Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 📦 Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: 🚀 Terraform Apply
      working-directory: ./terraform
      run: |
        # Déterminer l'environnement (même logique que terraform-plan)
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "🚀 Déploiement pour l'environnement: $ENVIRONMENT"
        
        terraform apply -auto-approve \
          -var="project_name=fode-devops" \
          -var="environment=$ENVIRONMENT" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: 📤 Export Terraform Outputs
      id: terraform-outputs
      working-directory: ./terraform
      run: |
        # Vérifier si les outputs existent avant de les extraire
        if terraform output load_balancer_dns >/dev/null 2>&1; then
          LB_DNS=$(terraform output -raw load_balancer_dns)
          echo "load_balancer_dns=$LB_DNS" >> $GITHUB_OUTPUT
        else
          echo "load_balancer_dns=non-disponible" >> $GITHUB_OUTPUT
        fi
        
        if terraform output instance_id >/dev/null 2>&1; then
          INSTANCE_ID=$(terraform output -raw instance_id)
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        else
          echo "instance_id=non-disponible" >> $GITHUB_OUTPUT
        fi
        
    - name: 📊 Create Deployment Summary
      working-directory: ./terraform
      run: |
        # Déterminer l'environnement pour l'affichage
        if [ "${{ github.event.inputs.action }}" != "" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "main" ]; then
          ENVIRONMENT="prod"
        elif [ "${{ github.ref_name }}" = "staging" ]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="dev"
        fi
        
        echo "## 🚀 Déploiement Fode-DevOps Réussi!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📋 Informations du déploiement:" >> $GITHUB_STEP_SUMMARY
        echo "- **Instance ID:** ${{ steps.terraform-outputs.outputs.instance_id }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Load Balancer DNS:** ${{ steps.terraform-outputs.outputs.load_balancer_dns }}" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.terraform-outputs.outputs.load_balancer_dns }}" != "non-disponible" ]; then
          echo "- **URL:** http://${{ steps.terraform-outputs.outputs.load_balancer_dns }}" >> $GITHUB_STEP_SUMMARY
        fi
        echo "- **Région:** ${{ env.AWS_DEFAULT_REGION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Environnement:** $ENVIRONMENT" >> $GITHUB_STEP_SUMMARY
    # =============================================================================
    # JOB 5B: ANSIBLE DEPLOYMENT - SSM ONLY
    # =============================================================================
  ansible-deployment:
    name: 🎭 Ansible Deployment (SSM)
    runs-on: ubuntu-latest
    needs: terraform-apply
    if: |
      always() && 
      needs.terraform-apply.result == 'success'

    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with: 
        python-version: '3.9'
        
    - name: 📦 Install Ansible and dependencies
      run: |
        python -m pip install --upgrade pip
        pip install ansible boto3 botocore
        # Installer les collections AWS pour SSM
        ansible-galaxy collection install amazon.aws community.aws
        ansible --version
        
    - name: 🔧 Install AWS Session Manager Plugin
      run: |
        curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb" -o "session-manager-plugin.deb"
        sudo dpkg -i session-manager-plugin.deb
        session-manager-plugin --version
        
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 🔧 Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        terraform_wrapper: false
        
    - name: 📦 Terraform Init (pour les outputs)
      working-directory: ./terraform
      run: terraform init
      
    - name: 🔍 Debug Terraform outputs
      working-directory: ./terraform
      run: |
        echo "📋 Outputs Terraform disponibles:"
        terraform output
        echo ""
        echo "🔍 Outputs spécifiques:"
        echo "Instance ID: $(terraform output -raw instance_id 2>/dev/null || echo 'N/A')"
        echo "S3 Bucket: $(terraform output -raw s3_bucket_name 2>/dev/null || echo 'N/A')"
        
    - name: 🔄 Générer inventaire Ansible
      run: |
        echo "📁 Structure des répertoires:"
        ls -la
        
        # Créer le répertoire inventory si nécessaire
        mkdir -p ansible/inventory
        
        # Rendre le script exécutable
        chmod +x ansible/scripts/generate_inventory.py
        
        # Exécuter le script depuis la racine du projet
        echo "🚀 Exécution du script de génération d'inventaire..."
        python3 ansible/scripts/generate_inventory.py
        
        echo ""
        echo "✅ Inventaire Ansible généré"
        
        # Vérifier que le fichier a été créé
        if [ -f "ansible/inventory/dynamic_hosts.json" ]; then
          echo "✅ Fichier d'inventaire créé avec succès"
          echo ""
          echo "📄 Contenu de l'inventaire:"
          cat ansible/inventory/dynamic_hosts.json
        else
          echo "❌ Échec de la création du fichier d'inventaire"
          exit 1
        fi
        
    - name: 🧪 Extract Instance Info
      id: extract_info
      run: |
        # Créer un script Python temporaire pour extraire les informations SSM
        cat > extract_info.py << 'EOF'
        import json
        import sys

        try:
            with open('ansible/inventory/dynamic_hosts.json', 'r') as f:
                inventory = json.load(f)
                
            # Extraction des informations depuis l'inventaire
            hostvars = inventory.get('_meta', {}).get('hostvars', {})
            server_info = hostvars.get('fode-web-server', {})
            
            instance_id = server_info.get('instance_id', 'N/A')
            ansible_connection = server_info.get('ansible_connection', 'aws_ssm')
            
            # Forcer la connexion SSM
            if ansible_connection != 'aws_ssm':
                print(f"⚠️ Connexion forcée vers SSM (était: {ansible_connection})")
                ansible_connection = 'aws_ssm'
            
            print(f"INSTANCE_ID={instance_id}")
            print(f"ANSIBLE_CONNECTION={ansible_connection}")
    
        except Exception as e:
            print(f"INSTANCE_ID=N/A")
            print(f"ANSIBLE_CONNECTION=aws_ssm")
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)
        EOF

        # Exécuter le script Python et capturer les variables
        python3 extract_info.py > inventory_vars.txt
        
        # Charger les variables dans l'environnement GitHub Actions
        while IFS= read -r line; do
          echo "$line" >> $GITHUB_OUTPUT
          echo "$line"
        done < inventory_vars.txt
        
        # Nettoyer
        rm extract_info.py inventory_vars.txt
        
    - name: 🧪 Test de connectivité SSM
      run: |
        echo "🔍 Variables extraites:"
        echo "Instance ID: ${{ steps.extract_info.outputs.INSTANCE_ID }}"
        echo "Ansible Connection: ${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
        
        INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
        
        if [ "$INSTANCE_ID" = "N/A" ]; then
          echo "❌ Instance ID non trouvé"
          exit 1
        fi
        
        echo "✅ Configuration SSM détectée"
        
        # Vérifier que l'instance est accessible via SSM
        aws ssm describe-instance-information \
          --filters "Key=InstanceIds,Values=$INSTANCE_ID" \
          --query 'InstanceInformationList[0].PingStatus' \
          --output text > ssm_status.txt
        
        SSM_STATUS=$(cat ssm_status.txt)
        echo "📊 Statut SSM: $SSM_STATUS"
        
        if [ "$SSM_STATUS" = "Online" ]; then
          echo "✅ Instance accessible via SSM"
          
          # Test simple via SSM
          echo "🧪 Test de commande via SSM..."
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["echo \"SSM Test OK\"","whoami","uptime"]' \
            --output text \
            --query 'Command.CommandId' > command_id.txt
          
          COMMAND_ID=$(cat command_id.txt)
          echo "📝 Command ID: $COMMAND_ID"
          
          # Attendre et récupérer le résultat
          sleep 10
          aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --query 'StandardOutputContent' \
            --output text || echo "⚠️ Impossible de récupérer la sortie de la commande"
            
        else
          echo "❌ Instance non accessible via SSM (Status: $SSM_STATUS)"
          echo "📋 Vérifications nécessaires :"
          echo "   - L'instance doit avoir le SSM Agent installé"
          echo "   - L'instance doit avoir un rôle IAM avec les permissions SSM"
          echo "   - L'instance doit être dans un sous-réseau avec accès à Internet ou VPC endpoints"
          exit 1
        fi
          
    - name: 🚀 Exécuter playbook Ansible
      working-directory: ./ansible
      run: |
        echo "📁 Vérification de la structure Ansible:"
        ls -la
        
        # Vérifier que les fichiers existent
        if [ ! -f "inventory/dynamic_hosts.json" ]; then
          echo "❌ Fichier d'inventaire manquant"
          exit 1
        fi
        
        if [ ! -f "playbooks/site.yml" ]; then
          echo "❌ Playbook principal manquant"
          echo "📁 Contenu du répertoire playbooks:"
          ls -la playbooks/ || echo "Répertoire playbooks non trouvé"
          exit 1
        fi
        
        INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
        
        echo "🔍 Instance ID: $INSTANCE_ID"
        echo "🔍 Connexion: AWS SSM"
        
        # Test de l'inventaire
        echo "🧪 Test de l'inventaire Ansible:"
        ansible-inventory -i inventory/dynamic_hosts.json --list
        
        echo ""
        echo "🔍 Test de connectivité Ansible via SSM:"
        
        # Utiliser des timeouts étendus pour SSM
        TIMEOUT=180
        CONNECTION_TIMEOUT=120
        echo "⏰ Utilisation de timeouts étendus pour SSM"
        
        # Test de ping SSM
        ansible all -i inventory/dynamic_hosts.json -m ping -v --timeout=$TIMEOUT || {
          echo "❌ Test de ping SSM échoué"
          echo "📋 Diagnostic SSM:"
          echo "   - Vérifiez que l'instance a le SSM Agent"
          echo "   - Vérifiez les permissions IAM"
          echo "   - Vérifiez la connectivité réseau"
          exit 1
        }
        
        echo ""
        echo "🚀 Exécution du playbook Ansible via SSM:"
        ansible-playbook -i inventory/dynamic_hosts.json playbooks/site.yml -v \
          --timeout=$TIMEOUT \
          --connection-timeout=$CONNECTION_TIMEOUT \
          || {
            echo "❌ Le playbook a échoué"
            
            echo "📋 Diagnostic SSM détaillé:"
            ansible all -i inventory/dynamic_hosts.json -m setup -a "filter=ansible_default_ipv4" --timeout=$TIMEOUT || echo "Impossible de récupérer les informations système via SSM"
            
            echo "📋 Vérifications SSM recommandées:"
            echo "   - Instance SSM Agent: sudo systemctl status amazon-ssm-agent"
            echo "   - Logs SSM: /var/log/amazon/ssm/"
            echo "   - Permissions IAM: AmazonSSMManagedInstanceCore"
            
            exit 1
          }
        
    - name: 📊 Résumé du déploiement Ansible
      if: always()
      run: |
        echo "## 🎭 Résumé du déploiement Ansible (SSM)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "ansible/inventory/dynamic_hosts.json" ]; then
          INSTANCE_ID="${{ steps.extract_info.outputs.INSTANCE_ID }}"
          ANSIBLE_CONNECTION="${{ steps.extract_info.outputs.ANSIBLE_CONNECTION }}"
          
          echo "- **Instance ID:** $INSTANCE_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **Type de connexion:** AWS Systems Manager (SSM)" >> $GITHUB_STEP_SUMMARY
          echo "- **Connexion Ansible:** $ANSIBLE_CONNECTION" >> $GITHUB_STEP_SUMMARY
          echo "- **Statut:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Inventaire:** ✅ Généré" >> $GITHUB_STEP_SUMMARY
          echo "- **SSM:** ✅ Configuré et testé" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "- **Déploiement:** ✅ Réussi" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Déploiement:** ❌ Échec" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🔧 Dépannage SSM" >> $GITHUB_STEP_SUMMARY
            echo "- Vérifiez le statut du SSM Agent sur l'instance" >> $GITHUB_STEP_SUMMARY
            echo "- Vérifiez les permissions IAM (AmazonSSMManagedInstanceCore)" >> $GITHUB_STEP_SUMMARY
            echo "- Vérifiez la connectivité réseau (Internet ou VPC endpoints)" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "- **Erreur:** Inventaire non généré" >> $GITHUB_STEP_SUMMARY
        fi

    # =============================================================================
    # JOB 6: TESTS POST-DÉPLOIEMENT
    # =============================================================================
  post-deployment-tests:
      name: 🧪 Tests Post-Déploiement
      runs-on: ubuntu-latest
      needs: [terraform-apply, ansible-deployment]
      if: |
        always() && 
        needs.terraform-apply.result == 'success' &&
        needs.ansible-deployment.result == 'success' &&
        needs.terraform-apply.outputs.load_balancer_dns != 'non-disponible'
      
      steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4
          
      - name: 🧪 Test Load Balancer
        run: |
          # Récupérer le DNS du Load Balancer
          LB_DNS="${{ needs.terraform-apply.outputs.load_balancer_dns }}"
          
          if [ "$LB_DNS" = "non-disponible" ] || [ -z "$LB_DNS" ]; then
            echo "⚠️ Load Balancer DNS non disponible, skip des tests"
            exit 0
          fi
          
          # Attendre que le Load Balancer soit prêt
          echo "⏳ Attente du démarrage du Load Balancer..."
          sleep 120
          
          # Test de connectivité HTTP
          echo "🌐 Test de connectivité HTTP via Load Balancer..."
          for i in {1..15}; do
            if curl -f -s http://$LB_DNS; then
              echo "✅ Load Balancer accessible!"
              break
            else
              echo "⏳ Tentative $i/15..."
              sleep 20
            fi
          done
          
          # Test de contenu
          echo "📄 Test du contenu..."
          CONTENT=$(curl -s http://$LB_DNS || echo "")
          if echo "$CONTENT" | grep -q "Fode-DevOps\|Welcome\|nginx\|Apache"; then
            echo "✅ Contenu correct détecté!"
          else
            echo "⚠️ Contenu inattendu, mais service accessible"
          fi

  # =============================================================================
  # JOB 7: TERRAFORM DESTROY
  # =============================================================================
  terraform-destroy:
    name: 💥 Terraform Destroy
    runs-on: ubuntu-latest
    needs: check-backend
    if: |
      always() && 
      (needs.check-backend.result == 'success' || needs.check-backend.result == 'skipped') &&
      github.event.inputs.action == 'destroy'
    environment: destruction
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🔧 Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
        
    - name: 🔑 Setup SSH Key
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
        chmod 600 ~/.ssh/id_rsa.pub
        mkdir -p ./terraform/keys
        cp ~/.ssh/id_rsa.pub ./terraform/keys/
        
    - name: 🔐 Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}
        
    - name: 📦 Terraform Init
      working-directory: ./terraform
      run: terraform init
      
    - name: 💥 Terraform Destroy
      working-directory: ./terraform
      run: |
        terraform destroy -auto-approve \
          -var="project_name=fode-devops" \
          -var="environment=prod" \
          -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
          -var="instance_type=t2.micro"
          
    - name: 📊 Destruction Summary
      run: |
        echo "## 💥 Infrastructure Fode-DevOps Détruite!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ⚠️ Toutes les ressources ont été supprimées" >> $GITHUB_STEP_SUMMARY
        echo "- **Région:** ${{ env.AWS_DEFAULT_REGION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Projet:** fode-devops" >> $GITHUB_STEP_SUMMARY